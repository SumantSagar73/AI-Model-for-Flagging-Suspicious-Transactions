{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ddc5b2",
   "metadata": {},
   "source": [
    "# ğŸ‡®ğŸ‡³ Indian Banking Fraud Detection System\n",
    "\n",
    "## Features of Indian Banking Dataset:\n",
    "- **Payment Methods**: UPI, RTGS, NEFT, IMPS, Net Banking\n",
    "- **Indian Merchants**: Kirana stores, Petrol pumps, Mobile recharge, etc.\n",
    "- **Regional Patterns**: Transactions across Indian states and cities\n",
    "- **Festival Patterns**: Higher transaction volumes during festivals\n",
    "- **Banking Hours**: Traditional banking hours (10 AM - 4 PM)\n",
    "- **RBI Compliance**: Indian banking regulations and patterns\n",
    "\n",
    "## Fraud Patterns Detected:\n",
    "- International transactions (higher risk)\n",
    "- Night-time transactions (2.5x risk)\n",
    "- Festival season fraud attempts (2x risk)\n",
    "- High-value transactions outside banking hours\n",
    "- Suspicious payment method combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938648df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for Indian banking analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set Indian locale for currency formatting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f16c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‡®ğŸ‡³ Loading Indian Banking Transaction Dataset...\n",
      "Dataset shape: (100000, 41)\n",
      "Memory usage: 55.35 MB\n",
      "\n",
      "ğŸ“Š Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 41 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Transaction_ID      100000 non-null  object \n",
      " 1   Timestamp           100000 non-null  object \n",
      " 2   Amount              100000 non-null  float64\n",
      " 3   Payment_Method      100000 non-null  object \n",
      " 4   Merchant_Category   100000 non-null  object \n",
      " 5   Location            100000 non-null  object \n",
      " 6   Hour                100000 non-null  int64  \n",
      " 7   Day_of_Week         100000 non-null  int64  \n",
      " 8   Is_Festival_Season  100000 non-null  bool   \n",
      " 9   Is_Banking_Hours    100000 non-null  bool   \n",
      " 10  Is_Weekend          100000 non-null  bool   \n",
      " 11  Month               100000 non-null  int64  \n",
      " 12  Class               100000 non-null  int64  \n",
      " 13  V1                  100000 non-null  float64\n",
      " 14  V2                  100000 non-null  float64\n",
      " 15  V3                  100000 non-null  float64\n",
      " 16  V4                  100000 non-null  float64\n",
      " 17  V5                  100000 non-null  float64\n",
      " 18  V6                  100000 non-null  float64\n",
      " 19  V7                  100000 non-null  float64\n",
      " 20  V8                  100000 non-null  float64\n",
      " 21  V9                  100000 non-null  float64\n",
      " 22  V10                 100000 non-null  float64\n",
      " 23  V11                 100000 non-null  float64\n",
      " 24  V12                 100000 non-null  float64\n",
      " 25  V13                 100000 non-null  float64\n",
      " 26  V14                 100000 non-null  float64\n",
      " 27  V15                 100000 non-null  float64\n",
      " 28  V16                 100000 non-null  float64\n",
      " 29  V17                 100000 non-null  float64\n",
      " 30  V18                 100000 non-null  float64\n",
      " 31  V19                 100000 non-null  float64\n",
      " 32  V20                 100000 non-null  float64\n",
      " 33  V21                 100000 non-null  float64\n",
      " 34  V22                 100000 non-null  float64\n",
      " 35  V23                 100000 non-null  float64\n",
      " 36  V24                 100000 non-null  float64\n",
      " 37  V25                 100000 non-null  float64\n",
      " 38  V26                 100000 non-null  float64\n",
      " 39  V27                 100000 non-null  float64\n",
      " 40  V28                 100000 non-null  float64\n",
      "dtypes: bool(3), float64(29), int64(4), object(5)\n",
      "memory usage: 29.3+ MB\n",
      "\n",
      "ğŸ’° Amount Statistics (in â‚¹):\n",
      "count    100000.000000\n",
      "mean       1624.608702\n",
      "std        5434.105723\n",
      "min           1.300000\n",
      "25%         199.000000\n",
      "50%         407.570000\n",
      "75%         857.167500\n",
      "max      123441.860000\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "ğŸš¨ Fraud Distribution:\n",
      "Legitimate: 95885 (95.88%)\n",
      "Fraudulent: 4115 (4.12%)\n"
     ]
    }
   ],
   "source": [
    "# Load Indian banking dataset\n",
    "print('ğŸ‡®ğŸ‡³ Loading Indian Banking Transaction Dataset...')\n",
    "df = pd.read_csv('../data/indian_banking_transactions.csv')\n",
    "\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB')\n",
    "\n",
    "# Display basic information\n",
    "print('\\nğŸ“Š Dataset Overview:')\n",
    "df.info()\n",
    "\n",
    "print('\\nğŸ’° Amount Statistics (in â‚¹):')\n",
    "print(df['Amount'].describe())\n",
    "\n",
    "print('\\nğŸš¨ Fraud Distribution:')\n",
    "fraud_counts = df['Class'].value_counts()\n",
    "print(f'Legitimate: {fraud_counts[0]} ({fraud_counts[0]/len(df)*100:.2f}%)')\n",
    "print(f'Fraudulent: {fraud_counts[1]} ({fraud_counts[1]/len(df)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc6d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ Indian Banking Pattern Analysis\n",
      "\n",
      "ğŸ“± Fraud Rate by Payment Method:\n",
      "                    Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Payment_Method                                                 \n",
      "International_Card                 421          421      1.0000\n",
      "UPI                              11161         1676      0.1502\n",
      "Net_Banking                      10841         1243      0.1147\n",
      "Mobile_Banking                   10237          775      0.0757\n",
      "Credit_Card                       9616            0      0.0000\n",
      "ATM_Withdrawal                    9625            0      0.0000\n",
      "Cash_Deposit                      9661            0      0.0000\n",
      "Debit_Card                        9737            0      0.0000\n",
      "IMPS                              9502            0      0.0000\n",
      "NEFT                              9552            0      0.0000\n",
      "RTGS                              9647            0      0.0000\n",
      "\n",
      "ğŸª Fraud Rate by Merchant Category:\n",
      "                   Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Merchant_Category                                             \n",
      "Gas_Cylinder                     4980          241      0.0484\n",
      "Mutual_Fund                      5055          241      0.0477\n",
      "E_Commerce                       5076          225      0.0443\n",
      "Petrol_Pump                      5088          224      0.0440\n",
      "Fixed_Deposit                    5059          216      0.0427\n",
      "Temple_Donation                  5048          215      0.0426\n",
      "Restaurant_Dhaba                 5027          211      0.0420\n",
      "Medical_Pharmacy                 4839          199      0.0411\n",
      "Auto_Rickshaw                    4830          198      0.0410\n",
      "Train_Booking                    5068          204      0.0403\n",
      "\n",
      "ğŸŒ Fraud Rate by Location:\n",
      "                         Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Location                                                            \n",
      "Border_Nepal                            191          191      1.0000\n",
      "Border_Bangladesh                       188          188      1.0000\n",
      "International_USA                       222          222      1.0000\n",
      "Unknown_Location                        204          204      1.0000\n",
      "International_Singapore                 197          197      1.0000\n",
      "International_Dubai                     219          219      1.0000\n",
      "Bhubaneswar_Odisha                     6139          196      0.0319\n",
      "Delhi_NCR                              6137          194      0.0316\n",
      "Hyderabad_Telangana                    6115          192      0.0314\n",
      "Chennai_Tamil_Nadu                     6077          190      0.0313\n",
      "\n",
      "â° Fraud Rate by Hour:\n",
      "      Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Hour                                             \n",
      "0                   1011           93      0.0920\n",
      "1                   1119          104      0.0929\n",
      "2                   1052          121      0.1150\n",
      "3                   1030          115      0.1117\n",
      "4                   1012          128      0.1265\n",
      "5                   1049          113      0.1077\n",
      "6                   2075           75      0.0361\n",
      "7                   2102           63      0.0300\n",
      "8                   2036           74      0.0363\n",
      "9                   8078          296      0.0366\n",
      "10                  8086          293      0.0362\n",
      "11                  8177          313      0.0383\n",
      "12                  4053          146      0.0360\n",
      "13                  4005          153      0.0382\n",
      "14                  8167          296      0.0362\n",
      "15                  8093          305      0.0377\n",
      "16                  8246          284      0.0344\n",
      "17                  2050           67      0.0327\n",
      "18                  6196          221      0.0357\n",
      "19                  6116          222      0.0363\n",
      "20                  6075          229      0.0377\n",
      "21                  6076          238      0.0392\n",
      "22                  1976           84      0.0425\n",
      "23                  2120           82      0.0387\n",
      "\n",
      "ğŸ‰ Festival Season Impact:\n",
      "                 Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Normal Period                 75836         2578      0.0340\n",
      "Festival Season               24164         1537      0.0636\n"
     ]
    }
   ],
   "source": [
    "# Indian Banking EDA\n",
    "print('ğŸ¦ Indian Banking Pattern Analysis')\n",
    "\n",
    "# Payment method analysis\n",
    "print('\\nğŸ“± Fraud Rate by Payment Method:')\n",
    "payment_fraud = df.groupby('Payment_Method')['Class'].agg(['count', 'sum', 'mean']).round(4)\n",
    "payment_fraud.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "payment_fraud = payment_fraud.sort_values('Fraud_Rate', ascending=False)\n",
    "print(payment_fraud)\n",
    "\n",
    "# Merchant category analysis\n",
    "print('\\nğŸª Fraud Rate by Merchant Category:')\n",
    "merchant_fraud = df.groupby('Merchant_Category')['Class'].agg(['count', 'sum', 'mean']).round(4)\n",
    "merchant_fraud.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "merchant_fraud = merchant_fraud.sort_values('Fraud_Rate', ascending=False)\n",
    "print(merchant_fraud.head(10))\n",
    "\n",
    "# Location analysis\n",
    "print('\\nğŸŒ Fraud Rate by Location:')\n",
    "location_fraud = df.groupby('Location')['Class'].agg(['count', 'sum', 'mean']).round(4)\n",
    "location_fraud.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "location_fraud = location_fraud.sort_values('Fraud_Rate', ascending=False)\n",
    "print(location_fraud.head(10))\n",
    "\n",
    "# Time-based analysis\n",
    "print('\\nâ° Fraud Rate by Hour:')\n",
    "hourly_fraud = df.groupby('Hour')['Class'].agg(['count', 'sum', 'mean']).round(4)\n",
    "hourly_fraud.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "print(hourly_fraud)\n",
    "\n",
    "# Festival season analysis\n",
    "print('\\nğŸ‰ Festival Season Impact:')\n",
    "festival_fraud = df.groupby('Is_Festival_Season')['Class'].agg(['count', 'sum', 'mean']).round(4)\n",
    "festival_fraud.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "festival_fraud.index = ['Normal Period', 'Festival Season']\n",
    "print(festival_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2922436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ› ï¸ Feature Engineering for Indian Banking Patterns...\n",
      "âœ… Feature engineering completed!\n",
      "Total features available: 50\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering for Indian Banking\n",
    "print('ğŸ› ï¸ Feature Engineering for Indian Banking Patterns...')\n",
    "\n",
    "# Create a copy for modeling\n",
    "df_model = df.copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le_payment = LabelEncoder()\n",
    "le_merchant = LabelEncoder()\n",
    "le_location = LabelEncoder()\n",
    "\n",
    "df_model['Payment_Method_Encoded'] = le_payment.fit_transform(df_model['Payment_Method'])\n",
    "df_model['Merchant_Category_Encoded'] = le_merchant.fit_transform(df_model['Merchant_Category'])\n",
    "df_model['Location_Encoded'] = le_location.fit_transform(df_model['Location'])\n",
    "\n",
    "# Create risk indicators\n",
    "df_model['Is_High_Risk_Payment'] = df_model['Payment_Method'].isin(['UPI', 'Net_Banking', 'International_Card']).astype(int)\n",
    "df_model['Is_International'] = df_model['Location'].str.contains('International').astype(int)\n",
    "df_model['Is_High_Value'] = (df_model['Amount'] > df_model['Amount'].quantile(0.95)).astype(int)\n",
    "df_model['Is_Night_Transaction'] = ((df_model['Hour'] < 6) | (df_model['Hour'] > 22)).astype(int)\n",
    "df_model['Amount_Log'] = np.log1p(df_model['Amount'])\n",
    "\n",
    "# Convert timestamp to unix timestamp for modeling\n",
    "df_model['Timestamp'] = pd.to_datetime(df_model['Timestamp'])\n",
    "df_model['Time_Numeric'] = df_model['Timestamp'].astype(int) // 10**9\n",
    "\n",
    "print('âœ… Feature engineering completed!')\n",
    "print(f'Total features available: {len(df_model.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63483e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Preparing Features for Indian Banking Model...\n",
      "Feature matrix shape: (100000, 44)\n",
      "Features used: 44\n",
      "Target distribution - Fraud: 4115 (4.115%)\n",
      "Training set: (80000, 44)\n",
      "Test set: (20000, 44)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for modeling\n",
    "print('ğŸ¯ Preparing Features for Indian Banking Model...')\n",
    "\n",
    "# Select features for modeling\n",
    "feature_columns = [col for col in df_model.columns if col.startswith('V')] + [\n",
    "    'Amount', 'Amount_Log', 'Time_Numeric', 'Hour', 'Day_of_Week', 'Month',\n",
    "    'Payment_Method_Encoded', 'Merchant_Category_Encoded', 'Location_Encoded',\n",
    "    'Is_Banking_Hours', 'Is_Weekend', 'Is_Festival_Season',\n",
    "    'Is_High_Risk_Payment', 'Is_International', 'Is_High_Value', 'Is_Night_Transaction'\n",
    "]\n",
    "\n",
    "X = df_model[feature_columns]\n",
    "y = df_model['Class']\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')\n",
    "print(f'Features used: {len(feature_columns)}')\n",
    "print(f'Target distribution - Fraud: {y.sum()} ({y.mean():.3%})')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set: {X_train_scaled.shape}')\n",
    "print(f'Test set: {X_test_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36117f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš–ï¸ Handling Class Imbalance...\n",
      "Before SMOTE - Fraud cases: 3292 (4.115%)\n",
      "After SMOTE - Total samples: 153416\n",
      "After SMOTE - Fraud cases: 76708 (50.000%)\n",
      "âœ… Dataset is now balanced for training!\n"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance with SMOTE\n",
    "print('âš–ï¸ Handling Class Imbalance...')\n",
    "\n",
    "print(f'Before SMOTE - Fraud cases: {y_train.sum()} ({y_train.mean():.3%})')\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f'After SMOTE - Total samples: {len(X_train_balanced)}')\n",
    "print(f'After SMOTE - Fraud cases: {y_train_balanced.sum()} ({y_train_balanced.mean():.3%})')\n",
    "\n",
    "print('âœ… Dataset is now balanced for training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c4c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Training Indian Banking Fraud Detection Models...\n",
      "\n",
      "ğŸ”¥ Training Logistic Regression...\n",
      "ğŸ¯ Logistic Regression Results:\n",
      "   AUC Score: 0.9923\n",
      "   Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      0.97      0.98     19177\n",
      "       Fraud       0.58      0.94      0.71       823\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.79      0.95      0.85     20000\n",
      "weighted avg       0.98      0.97      0.97     20000\n",
      "\n",
      "\n",
      "ğŸ”¥ Training Random Forest...\n",
      "ğŸ¯ Random Forest Results:\n",
      "   AUC Score: 0.9973\n",
      "   Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      0.98      0.99     19177\n",
      "       Fraud       0.73      0.96      0.83       823\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.86      0.97      0.91     20000\n",
      "weighted avg       0.99      0.98      0.98     20000\n",
      "\n",
      "\n",
      "ğŸ”¥ Training Gradient Boosting...\n",
      "ğŸ¯ Gradient Boosting Results:\n",
      "   AUC Score: 0.9993\n",
      "   Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      0.99      1.00     19177\n",
      "       Fraud       0.89      0.97      0.93       823\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.94      0.98      0.96     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "\n",
      "ğŸ”¥ Training XGBoost...\n",
      "ğŸ¯ XGBoost Results:\n",
      "   AUC Score: 0.9996\n",
      "   Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00     19177\n",
      "       Fraud       0.96      0.95      0.96       823\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.98      0.98      0.98     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "\n",
      "ğŸ† Best Model: XGBoost\n",
      "ğŸ¯ Best AUC Score: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# Train Indian Banking Fraud Detection Models\n",
    "print('ğŸ¤– Training Indian Banking Fraud Detection Models...')\n",
    "\n",
    "# Define models optimized for Indian banking patterns\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, max_depth=6, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\nğŸ”¥ Training {name}...')\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f'ğŸ¯ {name} Results:')\n",
    "    print(f'   AUC Score: {auc_score:.4f}')\n",
    "    print(f'   Classification Report:')\n",
    "    print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'auc': auc_score,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_auc = results[best_model_name]['auc']\n",
    "\n",
    "print(f'\\nğŸ† Best Model: {best_model_name}')\n",
    "print(f'ğŸ¯ Best AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9509e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Feature Importance Analysis for Indian Banking...\n",
      "ğŸ” Top 15 Most Important Features:\n",
      "                   feature  importance\n",
      "40    Is_High_Risk_Payment    0.693226\n",
      "41        Is_International    0.099312\n",
      "34  Payment_Method_Encoded    0.046287\n",
      "29              Amount_Log    0.034455\n",
      "28                  Amount    0.018958\n",
      "0                       V1    0.010752\n",
      "3                       V4    0.010268\n",
      "6                       V7    0.007859\n",
      "8                       V9    0.007527\n",
      "2                       V3    0.007349\n",
      "7                       V8    0.007035\n",
      "1                       V2    0.006653\n",
      "9                      V10    0.006445\n",
      "5                       V6    0.006411\n",
      "4                       V5    0.005966\n",
      "\n",
      "ğŸ‡®ğŸ‡³ Indian Banking Specific Feature Importance:\n",
      "                   feature  importance\n",
      "40    Is_High_Risk_Payment    0.693226\n",
      "41        Is_International    0.099312\n",
      "34  Payment_Method_Encoded    0.046287\n",
      "29              Amount_Log    0.034455\n",
      "39      Is_Festival_Season    0.005096\n",
      "43    Is_Night_Transaction    0.001706\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "print('ğŸ“Š Feature Importance Analysis for Indian Banking...')\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print('ğŸ” Top 15 Most Important Features:')\n",
    "    print(feature_importance_df.head(15))\n",
    "    \n",
    "    # Indian banking specific insights\n",
    "    indian_features = feature_importance_df[\n",
    "        feature_importance_df['feature'].isin([\n",
    "            'Is_International', 'Is_High_Risk_Payment', 'Payment_Method_Encoded',\n",
    "            'Is_Night_Transaction', 'Is_Festival_Season', 'Amount_Log'\n",
    "        ])\n",
    "    ]\n",
    "    print('\\nğŸ‡®ğŸ‡³ Indian Banking Specific Feature Importance:')\n",
    "    print(indian_features)\n",
    "else:\n",
    "    print('Feature importance not available for this model type.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b37cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving Indian Banking Fraud Detection Model...\n",
      "âœ… Saved XGBoost model with 0.9996 AUC score\n",
      "âœ… Saved scaler and encoders\n",
      "âœ… Saved feature column names\n",
      "\n",
      "ğŸ‰ Indian Banking Fraud Detection System Ready!\n",
      "\n",
      "ğŸ“‹ Model Performance Summary:\n",
      "   â€¢ Model Type: XGBoost\n",
      "   â€¢ AUC Score: 0.9996\n",
      "   â€¢ Training Samples: 153,416\n",
      "   â€¢ Test Samples: 20,000\n",
      "   â€¢ Features Used: 44\n",
      "   â€¢ Fraud Detection Rate: 817/20000\n",
      "\n",
      "ğŸš€ Ready for deployment in Indian banking environment!\n"
     ]
    }
   ],
   "source": [
    "# Save Indian Banking Model and Components\n",
    "print('ğŸ’¾ Saving Indian Banking Fraud Detection Model...')\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, '../backend/app/model/indian_banking_model.pkl')\n",
    "joblib.dump(scaler, '../backend/app/model/indian_banking_scaler.pkl')\n",
    "\n",
    "# Save encoders for categorical variables\n",
    "joblib.dump(le_payment, '../backend/app/model/payment_encoder.pkl')\n",
    "joblib.dump(le_merchant, '../backend/app/model/merchant_encoder.pkl')\n",
    "joblib.dump(le_location, '../backend/app/model/location_encoder.pkl')\n",
    "\n",
    "# Save feature columns list\n",
    "joblib.dump(feature_columns, '../backend/app/model/feature_columns.pkl')\n",
    "\n",
    "print(f'âœ… Saved {best_model_name} model with {best_auc:.4f} AUC score')\n",
    "print('âœ… Saved scaler and encoders')\n",
    "print('âœ… Saved feature column names')\n",
    "\n",
    "print('\\nğŸ‰ Indian Banking Fraud Detection System Ready!')\n",
    "print('\\nğŸ“‹ Model Performance Summary:')\n",
    "print(f'   â€¢ Model Type: {best_model_name}')\n",
    "print(f'   â€¢ AUC Score: {best_auc:.4f}')\n",
    "print(f'   â€¢ Training Samples: {len(X_train_balanced):,}')\n",
    "print(f'   â€¢ Test Samples: {len(X_test):,}')\n",
    "print(f'   â€¢ Features Used: {len(feature_columns)}')\n",
    "print(f'   â€¢ Fraud Detection Rate: {(results[best_model_name][\"predictions\"] == 1).sum()}/{len(y_test)}')\n",
    "\n",
    "print('\\nğŸš€ Ready for deployment in Indian banking environment!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
