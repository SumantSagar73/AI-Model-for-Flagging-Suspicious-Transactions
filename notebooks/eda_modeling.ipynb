{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7239a60c",
   "metadata": {},
   "source": [
    "# EDA & Model Development for Fraud Detection\n",
    "\n",
    "- Load and explore the dataset\n",
    "- Preprocess: scaling, handle imbalance\n",
    "- Train baseline models: Logistic Regression, Random Forest, XGBoost\n",
    "- Save best model for backend integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebd77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504a3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (50000, 37)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 37 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   V1             50000 non-null  float64\n",
      " 1   V2             50000 non-null  float64\n",
      " 2   V3             50000 non-null  float64\n",
      " 3   V4             50000 non-null  float64\n",
      " 4   V5             50000 non-null  float64\n",
      " 5   V6             50000 non-null  float64\n",
      " 6   V7             50000 non-null  float64\n",
      " 7   V8             50000 non-null  float64\n",
      " 8   V9             50000 non-null  float64\n",
      " 9   V10            50000 non-null  float64\n",
      " 10  V11            50000 non-null  float64\n",
      " 11  V12            50000 non-null  float64\n",
      " 12  V13            50000 non-null  float64\n",
      " 13  V14            50000 non-null  float64\n",
      " 14  V15            50000 non-null  float64\n",
      " 15  V16            50000 non-null  float64\n",
      " 16  V17            50000 non-null  float64\n",
      " 17  V18            50000 non-null  float64\n",
      " 18  V19            50000 non-null  float64\n",
      " 19  V20            50000 non-null  float64\n",
      " 20  V21            50000 non-null  float64\n",
      " 21  V22            50000 non-null  float64\n",
      " 22  V23            50000 non-null  float64\n",
      " 23  V24            50000 non-null  float64\n",
      " 24  V25            50000 non-null  float64\n",
      " 25  V26            50000 non-null  float64\n",
      " 26  V27            50000 non-null  float64\n",
      " 27  V28            50000 non-null  float64\n",
      " 28  Time           50000 non-null  float64\n",
      " 29  Amount         50000 non-null  float64\n",
      " 30  Merchant_Type  50000 non-null  object \n",
      " 31  Location       50000 non-null  object \n",
      " 32  Class          50000 non-null  int64  \n",
      " 33  Hour           50000 non-null  int64  \n",
      " 34  Day_of_Week    50000 non-null  int64  \n",
      " 35  Is_Weekend     50000 non-null  bool   \n",
      " 36  Is_Night       50000 non-null  bool   \n",
      "dtypes: bool(2), float64(30), int64(3), object(2)\n",
      "memory usage: 13.4+ MB\n",
      "\n",
      "First few rows:\n",
      "\n",
      "Fraud distribution:\n",
      "Class\n",
      "0    48626\n",
      "1     1374\n",
      "Name: count, dtype: int64\n",
      "Fraud rate: 2.748%\n",
      "\n",
      "Fraud by Merchant Type:\n",
      "                  Total_Transactions  Fraud_Cases  Fraud_Rate\n",
      "Merchant_Type                                                \n",
      "Grocery Store                   3925          130       0.033\n",
      "Hotel                           3760          111       0.030\n",
      "Pharmacy                        3808          112       0.029\n",
      "Airlines                        3885          113       0.029\n",
      "Department Store                3900          108       0.028\n",
      "Coffee Shop                     3742          103       0.028\n",
      "Online Retailer                 3935          105       0.027\n",
      "Restaurant                      3947          108       0.027\n",
      "ATM Withdrawal                  3773           98       0.026\n",
      "Utility Payment                 3861          101       0.026\n",
      "Insurance                       3879          102       0.026\n",
      "Bank Transfer                   3796           92       0.024\n",
      "Gas Station                     3789           91       0.024\n",
      "\n",
      "Using 30 features for modeling\n",
      "Features: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Time', 'Amount']\n",
      "\n",
      "Before SMOTE:\n",
      "Fraud cases: 1374 (2.748%)\n",
      "\n",
      "After SMOTE:\n",
      "Total samples: 97252\n",
      "Fraud cases: 48626 (50.000%)\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Results:\n",
      "AUC: 0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      9730\n",
      "           1       0.90      0.86      0.88      9721\n",
      "\n",
      "    accuracy                           0.88     19451\n",
      "   macro avg       0.88      0.88      0.88     19451\n",
      "weighted avg       0.88      0.88      0.88     19451\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Results:\n",
      "AUC: 0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      9730\n",
      "           1       0.99      0.99      0.99      9721\n",
      "\n",
      "    accuracy                           0.99     19451\n",
      "   macro avg       0.99      0.99      0.99     19451\n",
      "weighted avg       0.99      0.99      0.99     19451\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Results:\n",
      "AUC: 0.9989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      9730\n",
      "           1       0.98      0.99      0.99      9721\n",
      "\n",
      "    accuracy                           0.99     19451\n",
      "   macro avg       0.99      0.99      0.99     19451\n",
      "weighted avg       0.99      0.99      0.99     19451\n",
      "\n",
      "\n",
      "Best model: Random Forest (AUC: 0.9994)\n",
      "\n",
      "Saved Random Forest model and scaler for backend use!\n",
      "\n",
      "Model is now ready for real-world transaction analysis!\n"
     ]
    }
   ],
   "source": [
    "# Load realistic banking dataset\n",
    "df = pd.read_csv('../data/realistic_transactions.csv')\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nDataset info:')\n",
    "df.info()\n",
    "print('\\nFirst few rows:')\n",
    "df.head()\n",
    "\n",
    "# EDA: Check class distribution\n",
    "print('\\nFraud distribution:')\n",
    "print(df['Class'].value_counts())\n",
    "print(f'Fraud rate: {df[\"Class\"].mean():.3%}')\n",
    "\n",
    "# Analyze merchant patterns\n",
    "print('\\nFraud by Merchant Type:')\n",
    "fraud_by_merchant = df.groupby('Merchant_Type')['Class'].agg(['count', 'sum', 'mean']).round(3)\n",
    "fraud_by_merchant.columns = ['Total_Transactions', 'Fraud_Cases', 'Fraud_Rate']\n",
    "print(fraud_by_merchant.sort_values('Fraud_Rate', ascending=False))\n",
    "\n",
    "# Select features for modeling (exclude categorical and derived features)\n",
    "feature_cols = [col for col in df.columns if col.startswith('V') or col in ['Time', 'Amount']]\n",
    "features = df[feature_cols]\n",
    "labels = df['Class']\n",
    "\n",
    "print(f'\\nUsing {len(feature_cols)} features for modeling')\n",
    "print('Features:', feature_cols)\n",
    "\n",
    "# Preprocessing: Scaling features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "print('\\nBefore SMOTE:')\n",
    "print(f'Fraud cases: {labels.sum()} ({labels.mean():.3%})')\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(features_scaled, labels)\n",
    "\n",
    "print('\\nAfter SMOTE:')\n",
    "print(f'Total samples: {len(X_res)}')\n",
    "print(f'Fraud cases: {y_res.sum()} ({y_res.mean():.3%})')\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train multiple models and compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'\\nTraining {name}...')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(f'{name} Results:')\n",
    "    print(f'AUC: {auc:.4f}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    results[name] = {'model': model, 'auc': auc}\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f'\\nBest model: {best_model_name} (AUC: {results[best_model_name][\"auc\"]:.4f})')\n",
    "\n",
    "# Save best model and scaler\n",
    "import joblib\n",
    "joblib.dump(best_model, '../backend/app/model/model.pkl')\n",
    "joblib.dump(scaler, '../backend/app/model/scaler.pkl')\n",
    "\n",
    "print(f'\\nSaved {best_model_name} model and scaler for backend use!')\n",
    "print('\\nModel is now ready for real-world transaction analysis!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
